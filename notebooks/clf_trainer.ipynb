{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "import datasets\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fname = \"../data/subset/case_info.json\"\n",
    "# cases_df = pd.read_json(data_fname, lines=True, orient=\"records\")[[\"id\", \"head_matter\", \"opinion_text\"]]\n",
    "# cases_df[\"text\"] = cases_df[\"head_matter\"] + \"\\n\" +  cases_df[\"opinion_text\"]\n",
    "# cases_df = cases_df[[\"id\", \"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"allenai/specter\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModel.from_pretrained(model_name, from_pt=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset(\"json\", data_files=data_fname, split=datasets.splits.Split(\"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_text(examples):\n",
    "    return {\"text\": [item[0] + \"\\n\" + item[1] for item in zip(examples['head_matter'], examples['opinion_text'])]}\n",
    "\n",
    "exclude_columns = [\"jurisdiction_id\",\"court_id\",\"decision_date\", \"head_matter\",\"opinion_text\",\"citation_ids\"]\n",
    "dataset=dataset.map(load_text, batched=True, num_proc=15, remove_columns=exclude_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(examples):\n",
    "    tokenized = tokenizer(examples[\"text\"],\n",
    "                          return_tensors=\"tf\",\n",
    "                          padding=True,\n",
    "                          truncation=True,\n",
    "                          max_length=512\n",
    "                         )\n",
    "    \n",
    "    return {'embeddings': model(**tokenized)[0][:,0,:].numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset.map(load_embeddings, batched=True, batch_size=256)\n",
    "dataset.save_to_disk(\"../data/subset/dataset_specter_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.add_faiss_index(column='embeddings')\n",
    "dataset.save_faiss_index('embeddings', 'embeddings.faiss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.Dataset.load_from_disk(\"../data/subset/dataset_specter_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fname = \"../data/subset/train_map.csv\"\n",
    "val_fname = \"../data/subset/val_map.csv\"\n",
    "test_fname = \"../data/subset/test_map.csv\"\n",
    "\n",
    "\n",
    "def fix_nulls_and_types(fname):\n",
    "    df = pd.read_csv(fname)\n",
    "    df = df.dropna()\n",
    "    df = df.astype(int)\n",
    "    df.to_csv(fname, index=False, index_label=False)\n",
    "    return df\n",
    "# fix_nulls_and_types(train_fname)\n",
    "# fix_nulls_and_types(val_fname)\n",
    "# fix_nulls_and_types(test_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files={\n",
    "    \"train\": train_fname, \n",
    "    \"validation\": val_fname, \n",
    "    \"test\": test_fname,\n",
    "}\n",
    "clf_dataset = datasets.load_dataset(\"csv\", data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clf_embeddings(examples):\n",
    "    return {\n",
    "        \"case_embedding\": dataset[examples[\"id\"]][\"embeddings\"],\n",
    "        \"citation_embedding\": dataset[examples[\"citation\"]][\"embeddings\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_dataset = clf_dataset.map(load_clf_embeddings, batched=True, num_proc=15)\n",
    "clf_dataset.save_to_disk(\"../data/subset/clf_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_from_dataset(dataset):\n",
    "    def _gen():\n",
    "        for item in dataset:\n",
    "            features = (item[\"case_embedding\"], item[\"citation_embedding\"])\n",
    "            yield features, item['label']\n",
    "    return _gen\n",
    "\n",
    "def tf_dataset_from_dataset(dataset):\n",
    "    dataset_generator = generator_from_dataset(dataset)\n",
    "    tfdataset = tf.data.Dataset.from_generator(\n",
    "        dataset_generator,\n",
    "        output_signature=(\n",
    "         (tf.TensorSpec(shape=(768,), dtype=tf.float32),\n",
    "          tf.TensorSpec(shape=(768,), dtype=tf.float32),\n",
    "         ),\n",
    "         tf.TensorSpec(shape=(None), dtype=tf.int32))\n",
    "    )\n",
    "    tfdataset = tfdataset.apply(tf.data.experimental.assert_cardinality(len(dataset)))\n",
    "    return tfdataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_dataset_from_datasetv2(dataset):\n",
    "    features = (dataset['case_embedding'],\n",
    "                dataset['citation_embedding'])\n",
    "    labels = dataset['label']\n",
    "    return tf.data.Dataset.from_tensor_slices((features, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dataset = datasets.DatasetDict.load_from_disk(\"../data/subset/clf_dataset\", keep_in_memory=True)\n",
    "clf_dataset.set_format(type='tensorflow', columns=['case_embedding', 'citation_embedding', 'label'])\n",
    "\n",
    "train_dataset = clf_dataset['train']\n",
    "val_dataset = clf_dataset['validation']\n",
    "test_dataset = clf_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf_dataset_from_dataset(train_dataset)\n",
    "val_dataset = tf_dataset_from_dataset(val_dataset)\n",
    "test_dataset = tf_dataset_from_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_input = tf.keras.layers.Input(shape=(768,), dtype=tf.float32, name=\"case_input\")\n",
    "citation_input = tf.keras.layers.Input(shape=(768,), dtype=tf.float32, name=\"citation_input\")\n",
    "\n",
    "shared_stack = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.3,),\n",
    "    tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.3,),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "], name=\"shared_stack\")\n",
    "\n",
    "case_representation = shared_stack(case_input)\n",
    "citation_representation = shared_stack(citation_input)\n",
    "concatenated = tf.keras.layers.Concatenate()([case_representation, citation_representation])\n",
    "concatenated = tf.keras.layers.Dropout(0.3,)(concatenated)\n",
    "output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(concatenated)\n",
    "clf_model = tf.keras.models.Model(inputs=[case_input, citation_input], outputs=[output], name=\"clf_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"clf_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "case_input (InputLayer)         [(None, 768)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "citation_input (InputLayer)     [(None, 768)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shared_stack (Sequential)       (None, 64)           566208      case_input[0][0]                 \n",
      "                                                                 citation_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 128)          0           shared_stack[0][0]               \n",
      "                                                                 shared_stack[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            129         dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 566,337\n",
      "Trainable params: 566,337\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model.compile(loss=\"bce\", metrics=[\"binary_accuracy\"],  optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "\n",
    "train_dataset = train_dataset.repeat().shuffle(batch_size*4).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.repeat().batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.repeat().batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "             tf.keras.callbacks.ModelCheckpoint(\"../models/specter_matching_v1\", save_best_only=True,),\n",
    "             tf.keras.callbacks.CSVLogger(\"../models/logs/specter_matching_v1.csv\"),\n",
    "             tf.keras.callbacks.ReduceLROnPlateau(patience=3, verbose=1)\n",
    "            ]\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " 15/250 [>.............................] - ETA: 21:05 - loss: 0.6827 - binary_accuracy: 0.5527"
     ]
    }
   ],
   "source": [
    "history = clf_model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=250,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=100,\n",
    "    verbose=1,\n",
    "    epochs=15,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
